{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Scheduler for AID2E Documentation","text":"<p>Welcome to the documentation for the Scheduler library, a Python package for scheduling and managing optimization trials for the ePIC EIC detector design using Ax.</p>"},{"location":"#overview","title":"Overview","text":"<p>The Scheduler library extends the Ax platform for Bayesian optimization with additional features for managing and executing trials on various compute backends. It's designed to facilitate parameter optimization for detector simulations and other computationally intensive tasks.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Ax Integration: Seamlessly works with the Ax platform for Bayesian optimization</li> <li>Multiple Job Types:</li> <li>Python functions</li> <li>Shell/Python scripts</li> <li>Containers (Docker/Singularity)</li> <li>Multiple Execution Backends:</li> <li>JobLib for local parallel execution</li> <li>Slurm for cluster computing</li> <li>PanDA for distributed computing</li> <li>Trial Management: Comprehensive trial state tracking and monitoring</li> <li>Flexible Execution: Support for synchronous or asynchronous execution modes</li> <li>Batch Processing: Submit multiple trials in parallel for efficient exploration</li> <li>Persistence: Save and load experiments to resume optimization</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation: How to install the Scheduler library</li> <li>Quick Start: Get up and running with simple examples</li> <li>Tutorials: Step-by-step guides for common use cases</li> <li>API Reference: Detailed documentation of classes and methods</li> </ul>"},{"location":"#about-this-documentation","title":"About This Documentation","text":"<p>This documentation is built using MkDocs with the Material theme, customized to have a GitBook-like appearance. It includes:</p> <ul> <li>Comprehensive API reference</li> <li>Step-by-step tutorials</li> <li>Architectural overview</li> <li>Code examples</li> <li>Dark/light mode toggle</li> </ul> <p>The documentation source is available in the GitHub repository under the <code>docs/</code> directory. Contributions to improve the documentation are welcome!</p>"},{"location":"#architecture","title":"Architecture","text":"<p>See the Architecture Overview for a high-level understanding of how the components interact.</p>"},{"location":"404/","title":"404 - Page Not Found","text":"<p>The page you are looking for does not exist or has been moved.</p> <p>Return to Home</p>"},{"location":"architecture/","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                \u2502         \u2502               \u2502\n\u2502  Ax Platform   \u2502         \u2502  AxScheduler  \u2502\n\u2502                \u2502         \u2502               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                          \u2502\n        \u2502 extends                  \u2502 manages\n        \u25bc                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                \u2502         \u2502               \u2502\n\u2502  Ax Trial      \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u25ba  \u2502  Trial        \u2502\n\u2502                \u2502         \u2502               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u2502 contains\n                                   \u25bc\n                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                           \u2502               \u2502\n                           \u2502  Job          \u2502\n                           \u2502               \u2502\n                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u2502 executed by\n                                   \u25bc\n                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                 \u2502                             \u2502\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524        BaseRunner           \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502             \u2502                             \u2502            \u2502\n   \u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n   \u2502                                                        \u2502\n   \u25bc                          \u25bc                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             \u2502      \u2502               \u2502             \u2502               \u2502\n\u2502JobLibRunner \u2502      \u2502  SlurmRunner  \u2502             \u2502 PanDARunner   \u2502\n\u2502             \u2502      \u2502               \u2502             \u2502               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"github_pages_setup/","title":"Setting Up Documentation Hosting on GitHub","text":"<p>This guide explains how to set up hosting for your project documentation on GitHub Pages using MkDocs with the Material theme and a GitBook-like appearance.</p>"},{"location":"github_pages_setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>GitHub repository for your project</li> <li>Python 3.7+ installed</li> <li>Access to GitHub Actions</li> </ul>"},{"location":"github_pages_setup/#step-1-install-mkdocs-and-required-extensions","title":"Step 1: Install MkDocs and Required Extensions","text":"<p>First, create a requirements file for documentation dependencies (requirements-docs.txt):</p> <pre><code># Create a requirements file for documentation\ncat &gt; docs/requirements-docs.txt &lt;&lt; EOF\nmkdocs&gt;=1.4.0\nmkdocs-material&gt;=8.5.0\npymdown-extensions&gt;=9.0\ncairosvg&gt;=2.5.0\npillow&gt;=9.0.0\npygments&gt;=2.14.0\nEOF\n\n# Install the requirements\npip install -r docs/requirements-docs.txt\n</code></pre>"},{"location":"github_pages_setup/#step-2-create-documentation-directory-structure","title":"Step 2: Create Documentation Directory Structure","text":"<p>Create a <code>docs</code> directory in the root of your repository with the following structure:</p> <pre><code>docs/\n\u251c\u2500\u2500 index.md                  # Home page\n\u251c\u2500\u2500 installation.md           # Installation guide\n\u251c\u2500\u2500 quickstart.md             # Quick start guide\n\u251c\u2500\u2500 architecture.md           # Architecture overview\n\u251c\u2500\u2500 requirements-docs.txt     # Documentation dependencies\n\u251c\u2500\u2500 assets/                   # Images and other assets\n\u2502   \u251c\u2500\u2500 logo.png\n\u2502   \u2514\u2500\u2500 favicon.png\n\u251c\u2500\u2500 stylesheets/              # Custom CSS\n\u2502   \u2514\u2500\u2500 gitbook.css\n\u251c\u2500\u2500 api/                      # API documentation\n\u2502   \u2514\u2500\u2500 index.md\n\u2514\u2500\u2500 tutorials/                # Tutorials\n    \u2514\u2500\u2500 index.md\n</code></pre> <p>Create the base structure with:</p> <pre><code># Create the directory structure\nmkdir -p docs/assets docs/stylesheets docs/api docs/tutorials\n</code></pre>"},{"location":"github_pages_setup/#step-3-create-mkdocs-configuration","title":"Step 3: Create MkDocs Configuration","text":"<p>Create a file named <code>mkdocs.yml</code> in the root of your repository:</p> <pre><code>site_name: Scheduler for AID2E\nsite_description: A Python library for scheduling and managing optimization trials for the ePIC EIC detector design using Ax\nsite_author: AID2E Team\nsite_url: https://aid2e.github.io/scheduler_epic/\nrepo_url: https://github.com/aid2e/scheduler_epic\nrepo_name: aid2e/scheduler_epic\n\n# Theme configuration\ntheme:\n  name: material\n  logo: assets/logo.png\n  favicon: assets/favicon.png\n  palette:\n    # Light mode\n    - media: \"(prefers-color-scheme: light)\"\n      scheme: default\n      primary: indigo\n      accent: indigo\n      toggle:\n        icon: material/weather-night\n        name: Switch to dark mode\n    # Dark mode\n    - media: \"(prefers-color-scheme: dark)\"\n      scheme: slate\n      primary: indigo\n      accent: indigo\n      toggle:\n        icon: material/weather-sunny\n        name: Switch to light mode\n  features:\n    - navigation.tabs\n    - navigation.sections\n    - navigation.expand\n    - navigation.indexes\n    - navigation.top\n    - toc.follow\n    - content.code.copy\n    - content.code.annotate\n    - content.action.edit\n    - search.highlight\n    - search.suggest\n  icon:\n    repo: fontawesome/brands/github\n\n# Extra configuration\nextra:\n  social:\n    - icon: fontawesome/brands/github\n      link: https://github.com/aid2e/scheduler_epic\n      name: AID2E Scheduler on GitHub\n\n  # Add GitHub edit capabilities\n  repo_icon: github\n  edit_uri: edit/main/docs/\n\n# Add custom CSS to make it more GitBook-like\nextra_css:\n  - stylesheets/gitbook.css\n\n# Markdown extensions for richer content\nmarkdown_extensions:\n  - admonition\n  - attr_list\n  - def_list\n  - footnotes\n  - md_in_html\n  - toc:\n      permalink: true\n  - pymdownx.highlight:\n      anchor_linenums: true\n  - pymdownx.superfences\n  - pymdownx.inlinehilite\n  - pymdownx.snippets\n  - pymdownx.tabbed:\n      alternate_style: true \n  - pymdownx.tasklist:\n      custom_checkbox: true\n</code></pre> <p>This configuration includes: - Material theme with light/dark mode toggle - Custom GitBook-like styling - GitHub repository integration - Enhanced navigation features - Syntax highlighting and other Markdown extensions</p> <p>nav:   - Home: index.md   - Installation: installation.md   - Quick Start: quickstart.md   - Tutorials:     - tutorials/index.md     - Basic Detector Optimization: tutorials/detector_optimization.md     - Slurm Execution: tutorials/slurm_execution.md     - Container-Based Optimization: tutorials/container_based_optimization.md     - Batch Trial Submission: tutorials/batch_trial_submission.md   - API Reference:     - api/index.md     - AxScheduler: api/ax_scheduler.md     - Trial: api/trial.md     - Job: api/job.md     - Runners: api/runners.md   - Architecture: architecture.md <pre><code>## Step 4: Preview Documentation Locally\n\nYou can preview your documentation locally by running:\n\n```bash\nmkdocs serve\n</code></pre></p> <p>This will start a local server at http://127.0.0.1:8000/ where you can preview your documentation.</p>"},{"location":"github_pages_setup/#step-5-configure-github-actions-for-deployment","title":"Step 5: Configure GitHub Actions for Deployment","text":"<p>Create a GitHub Actions workflow file at <code>.github/workflows/deploy-docs.yml</code>:</p> <pre><code>name: Deploy Documentation\n\non:\n  push:\n    branches:\n      - main\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: write\n  pages: write\n  id-token: write\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n        with:\n          fetch-depth: 0\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          # Install Cairo for SVG support\n          sudo apt-get update\n          sudo apt-get install -y libcairo2-dev pkg-config python3-dev\n          # Install documentation requirements\n          pip install -r docs/requirements-docs.txt\n\n      - name: Configure Git\n        run: |\n          git config --global user.name \"github-actions[bot]\"\n          git config --global user.email \"github-actions[bot]@users.noreply.github.com\"\n\n      - name: Deploy documentation\n        run: |\n          # Try up to 3 times to deploy, handling potential race conditions\n          max_attempts=3\n          attempt=1\n\n          while [ $attempt -le $max_attempts ]; do\n            echo \"Deployment attempt $attempt of $max_attempts\"\n\n            if mkdocs gh-deploy --force --clean; then\n              echo \"Deployment successful!\"\n              break\n            else\n              if [ $attempt -eq $max_attempts ]; then\n                echo \"Failed all $max_attempts deployment attempts\"\n                exit 1\n              fi\n\n              echo \"Deployment attempt failed. Fetching latest changes and retrying...\"\n              git fetch origin gh-pages || true\n              sleep 5\n            fi\n\n            attempt=$((attempt+1))\n          done\n</code></pre> <p>This workflow includes retry logic to handle potential race conditions during deployment, which can sometimes occur with GitHub Pages.</p>"},{"location":"github_pages_setup/#step-6-enable-github-pages","title":"Step 6: Enable GitHub Pages","text":"<ol> <li>Go to your repository on GitHub</li> <li>Navigate to Settings &gt; Pages</li> <li>Under \"Source\", select \"GitHub Actions\"</li> <li>Commit and push your changes to the main branch</li> </ol> <p>After pushing your changes, GitHub Actions will automatically build and deploy your documentation to GitHub Pages. The documentation will be available at:</p> <pre><code>https://&lt;username&gt;.github.io/&lt;repository&gt;/\n</code></pre>"},{"location":"github_pages_setup/#step-7-add-a-link-to-your-documentation-in-readme","title":"Step 7: Add a Link to Your Documentation in README","text":"<p>Update your README.md to include a link to your documentation:</p> <pre><code>## Documentation\n\nComprehensive documentation is available at: https://aid2e.github.io/scheduler_epic/\n</code></pre>"},{"location":"github_pages_setup/#updating-documentation","title":"Updating Documentation","text":"<p>To update your documentation:</p> <ol> <li>Make changes to your Markdown files in the <code>docs/</code> directory</li> <li>Commit and push your changes to the main branch</li> <li>GitHub Actions will automatically rebuild and deploy your documentation</li> </ol>"},{"location":"github_pages_setup/#additional-configuration-options","title":"Additional Configuration Options","text":""},{"location":"github_pages_setup/#removing-the-left-navigation-sidebar","title":"Removing the Left Navigation Sidebar","text":"<p>If you want to remove the left navigation sidebar to reduce redundancy, modify the <code>features</code> section in your <code>mkdocs.yml</code>:</p> <pre><code>theme:\n  features:\n    # Remove these lines to disable the left sidebar\n    # - navigation.sections\n    # - navigation.expand\n    # - navigation.indexes\n\n    # Keep these features\n    - navigation.top\n    - toc.follow\n    - content.code.copy\n    - content.code.annotate\n    - content.action.edit\n    - search.highlight\n    - search.suggest\n    - navigation.tabs\n</code></pre> <p>You can also add custom CSS to hide the sidebar completely by adding this to <code>docs/stylesheets/gitbook.css</code>:</p> <pre><code>/* Hide the left sidebar completely */\n.md-sidebar--primary {\n  display: none !important;\n}\n\n/* Adjust the main content width when sidebar is hidden */\n.md-content {\n  max-width: 1000px;\n  margin: 0 auto;\n}\n</code></pre>"},{"location":"github_pages_setup/#adding-a-custom-domain","title":"Adding a Custom Domain","text":"<p>If you want to use a custom domain for your documentation:</p> <ol> <li>Go to your repository's Settings &gt; Pages</li> <li>Under \"Custom domain\", enter your domain name and save</li> <li>Create a CNAME file in the <code>docs/</code> directory with your domain name</li> </ol>"},{"location":"github_pages_setup/#adding-search-functionality","title":"Adding Search Functionality","text":"<p>MkDocs Material theme includes search functionality by default. You can customize it in the <code>mkdocs.yml</code> file:</p> <pre><code>plugins:\n  - search:\n      lang: en\n</code></pre>"},{"location":"github_pages_setup/#adding-analytics","title":"Adding Analytics","text":"<p>You can add Google Analytics to track documentation usage:</p> <pre><code>extra:\n  analytics:\n    provider: google\n    property: G-XXXXXXXXXX\n</code></pre> <p>Replace <code>G-XXXXXXXXXX</code> with your Google Analytics property ID.</p>"},{"location":"github_pages_setup/#gitbook-like-styling","title":"GitBook-Like Styling","text":"<p>To achieve a GitBook-like appearance for our documentation, we've added custom CSS. Create a file at <code>docs/stylesheets/gitbook.css</code>:</p> <pre><code>/* GitBook-like styles */\n:root {\n  --md-primary-fg-color: #4051b5;\n  --md-primary-fg-color--light: #7880c3;\n  --md-primary-fg-color--dark: #303fa1;\n}\n\n/* Make navigation sidebar more like GitBook */\n.md-sidebar--primary {\n  background-color: #fafafa;\n}\n\n[data-md-color-scheme=\"slate\"] .md-sidebar--primary {\n  background-color: #1e1e1e;\n}\n\n/* Improve readability of main content */\n.md-content {\n  max-width: 800px;\n  margin: 0 auto;\n  padding: 1rem 2rem;\n}\n\n/* Enhance code blocks */\n.highlight pre {\n  border-radius: 4px;\n}\n\n/* Make headings more prominent */\n.md-content h1 {\n  font-weight: 600;\n  margin-bottom: 2rem;\n  padding-bottom: 0.5rem;\n  border-bottom: 1px solid rgba(0, 0, 0, 0.1);\n}\n\n[data-md-color-scheme=\"slate\"] .md-content h1 {\n  border-bottom: 1px solid rgba(255, 255, 255, 0.1);\n}\n\n/* Nice link styling */\n.md-content a:not(.md-button) {\n  color: var(--md-primary-fg-color);\n  text-decoration: none;\n  border-bottom: 1px solid transparent;\n  transition: border-color 0.2s ease;\n}\n\n.md-content a:not(.md-button):hover {\n  border-bottom-color: var(--md-primary-fg-color);\n}\n</code></pre> <p>Then reference this CSS file in your <code>mkdocs.yml</code>:</p> <pre><code>extra_css:\n  - stylesheets/gitbook.css\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>This guide covers how to install the Scheduler library for AID2E.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.7 or later</li> <li>pip package manager</li> </ul>"},{"location":"installation/#basic-installation","title":"Basic Installation","text":"<p>You can install the Scheduler library from source:</p> <pre><code># Clone the repository\ngit clone https://github.com/aid2e/scheduler_epic\ncd scheduler\n\n# Install the basic package\npip install -e .\n</code></pre>"},{"location":"installation/#installation-with-specific-backends","title":"Installation with Specific Backends","text":"<p>The Scheduler supports different execution backends. You can install the dependencies for the ones you need:</p>"},{"location":"installation/#with-slurm-support","title":"With Slurm Support","text":"<pre><code>pip install -e .[slurm]\n</code></pre>"},{"location":"installation/#with-panda-support","title":"With PanDA Support","text":"<pre><code>pip install -e .[panda]\n</code></pre>"},{"location":"installation/#with-all-features","title":"With All Features","text":"<pre><code>pip install -e .[slurm,panda]\n</code></pre>"},{"location":"installation/#development-installation","title":"Development Installation","text":"<p>For development purposes, you may want to install the development dependencies:</p> <pre><code>pip install -e .[dev]\n</code></pre> <p>or</p> <pre><code>pip install -r requirements-dev.txt\n</code></pre>"},{"location":"installation/#verifying-installation","title":"Verifying Installation","text":"<p>You can verify that the installation was successful by running:</p> <pre><code>import scheduler\nprint(scheduler.__version__)\n</code></pre> <p>This should print the version number of the installed package.</p>"},{"location":"installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Local Execution (JobLibRunner): Any system with Python and sufficient RAM/CPU for your tasks</li> <li>Slurm Execution (SlurmRunner): Access to a Slurm cluster</li> <li>PanDA Execution (PanDARunner): Access to the PanDA distributed computing system</li> </ul>"},{"location":"quickstart/","title":"Quick Start","text":"<p>This guide will help you get started with the Scheduler library quickly. We'll cover the basic workflow for setting up and running an optimization experiment.</p>"},{"location":"quickstart/#basic-workflow","title":"Basic Workflow","text":"<p>The typical workflow for using the Scheduler involves:</p> <ol> <li>Defining your parameter space with Ax</li> <li>Creating a runner for job execution</li> <li>Setting up the scheduler with your objective function</li> <li>Running the optimization</li> </ol>"},{"location":"quickstart/#simple-example","title":"Simple Example","text":"<p>Here's a minimal example that optimizes a simple function:</p> <pre><code>from ax.service.ax_client import AxClient\nfrom scheduler import AxScheduler, JobLibRunner\n\n# 1. Initialize Ax client and define parameter space\nax_client = AxClient()\nax_client.create_experiment(\n    name=\"my_experiment\",\n    parameters=[\n        {\n            \"name\": \"x\",\n            \"type\": \"range\",\n            \"bounds\": [0.0, 1.0],\n            \"value_type\": \"float\",\n        },\n        {\n            \"name\": \"y\",\n            \"type\": \"range\",\n            \"bounds\": [0.0, 1.0],\n            \"value_type\": \"float\",\n        },\n    ],\n    objectives={\"objective\": \"minimize\"},\n)\n\n# 2. Define your objective function\ndef objective_function(parameterization):\n    x = parameterization[\"x\"]\n    y = parameterization[\"y\"]\n    return {\"objective\": (x - 0.5)**2 + (y - 0.5)**2}\n\n# 3. Create a runner for local execution\nrunner = JobLibRunner(n_jobs=-1)  # Use all available cores\n\n# 4. Create the scheduler\nscheduler = AxScheduler(ax_client, runner)\n\n# 5. Set the objective function\nscheduler.set_objective_function(objective_function)\n\n# 6. Run the optimization\nbest_params = scheduler.run_optimization(max_trials=10)\nprint(\"Best parameters:\", best_params)\n</code></pre> <p>This example: - Creates an experiment with two parameters (x and y) - Defines a simple quadratic objective function - Uses the JobLibRunner for local parallel execution - Runs 10 trials to find the optimal parameter values</p>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<p>For more advanced usage, check out:</p> <ul> <li>Tutorial: Detector Optimization</li> <li>Tutorial: Using Slurm for Execution</li> <li>Tutorial: Container-Based Jobs</li> <li>API Reference: AxScheduler</li> <li>API Reference: Runners</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>This section provides detailed documentation for the classes and methods in the Scheduler library.</p>"},{"location":"api/#core-components","title":"Core Components","text":"<ul> <li>AxScheduler: Main scheduler class that integrates with Ax</li> <li>Trial: Trial class for managing optimization trials</li> <li>Job: Job class for different types of execution tasks</li> <li>Runners: Various execution backends</li> </ul>"},{"location":"api/#module-index","title":"Module Index","text":"<ul> <li><code>scheduler.ax_scheduler</code>: Integration with Ax for optimization</li> <li><code>scheduler.trial</code>: Trial management and state tracking</li> <li><code>scheduler.job</code>: Job execution and state management</li> <li><code>scheduler.runners</code>: Different execution backends (JobLib, Slurm, PanDA)</li> <li><code>scheduler.monitoring</code>: Monitoring and event handling</li> <li><code>scheduler.utils</code>: Utility functions and helpers</li> </ul>"},{"location":"api/ax_scheduler/","title":"AxScheduler","text":"<p>The <code>AxScheduler</code> class is the main entry point for using the Scheduler library. It integrates with Ax for optimization and manages the execution of trials.</p>"},{"location":"api/ax_scheduler/#class-definition","title":"Class Definition","text":"<pre><code>class AxScheduler:\n    def __init__(self, \n                 ax_client_or_experiment: Union[AxClient, Experiment], \n                 runner: BaseRunner, \n                 config: Dict[str, Any] = None):\n        \"\"\"\n        Initialize a new AxScheduler.\n\n        Args:\n            ax_client_or_experiment: The Ax client or experiment to use for optimization\n            runner: The runner to use for executing jobs\n            config: Additional configuration options\n        \"\"\"\n</code></pre>"},{"location":"api/ax_scheduler/#key-methods","title":"Key Methods","text":""},{"location":"api/ax_scheduler/#setting-objective-functions","title":"Setting Objective Functions","text":"<pre><code>def set_objective_function(self, function: Callable[[Dict[str, Any]], Dict[str, Any]]) -&gt; None:\n    \"\"\"\n    Set the objective function to use for trials.\n\n    Args:\n        function: A function that takes a dict of parameters and returns a dict of metrics\n    \"\"\"\n</code></pre> <pre><code>def set_script_objective(self, script_path: str, script_options: Dict[str, Any] = None) -&gt; None:\n    \"\"\"\n    Set a script as the objective function.\n\n    Args:\n        script_path: Path to the script to run\n        script_options: Additional options for script execution\n    \"\"\"\n</code></pre> <pre><code>def set_container_objective(self, container_image: str, container_command: str,\n                         container_options: Dict[str, Any] = None) -&gt; None:\n    \"\"\"\n    Set a container as the objective function.\n\n    Args:\n        container_image: Container image to run\n        container_command: Command to run in the container\n        container_options: Additional options for container execution\n    \"\"\"\n</code></pre>"},{"location":"api/ax_scheduler/#running-optimization","title":"Running Optimization","text":"<pre><code>def run_optimization(self, max_trials: int = 10, timeout: Optional[float] = None,\n                  synchronous: Optional[bool] = None) -&gt; Dict[str, Any]:\n    \"\"\"\n    Run the optimization process.\n\n    Args:\n        max_trials: Maximum number of trials to run\n        timeout: Maximum time to run the optimization (in seconds)\n        synchronous: Whether to run trials synchronously\n\n    Returns:\n        The best parameters found\n    \"\"\"\n</code></pre>"},{"location":"api/ax_scheduler/#batch-trial-submission","title":"Batch Trial Submission","text":"<pre><code>@contextmanager\ndef batch_trial_context(self) -&gt; \"BatchTrialContext\":\n    \"\"\"\n    Context manager for batch trial submission.\n\n    Usage:\n        with scheduler.batch_trial_context() as batch:\n            batch.add_trial({\"x\": 0.1, \"y\": 0.2})\n            batch.add_trial({\"x\": 0.3, \"y\": 0.4})\n    \"\"\"\n</code></pre>"},{"location":"api/ax_scheduler/#experiment-persistence","title":"Experiment Persistence","text":"<pre><code>def save_experiment(self, path: str) -&gt; None:\n    \"\"\"\n    Save the current experiment to a file.\n\n    Args:\n        path: Path to save the experiment to\n    \"\"\"\n</code></pre> <pre><code>def load_experiment(self, path: str) -&gt; None:\n    \"\"\"\n    Load an experiment from a file.\n\n    Args:\n        path: Path to load the experiment from\n    \"\"\"\n</code></pre>"},{"location":"api/ax_scheduler/#configuration-options","title":"Configuration Options","text":"<p>The <code>AxScheduler</code> accepts a configuration dictionary with the following options:</p> Option Type Default Description <code>monitoring_interval</code> int 10 Seconds between status checks <code>job_output_dir</code> str './outputs' Directory for job outputs <code>synchronous</code> bool True Run trials synchronously <code>cleanup_after_completion</code> bool True Clean up files after completion"},{"location":"api/ax_scheduler/#example-usage","title":"Example Usage","text":"<pre><code># Create a scheduler with custom configuration\nscheduler = AxScheduler(\n    ax_client, \n    runner,\n    config={\n        'monitoring_interval': 5,  # Check status every 5 seconds\n        'job_output_dir': './trial_outputs',  # Custom output directory\n        'synchronous': False,  # Run trials asynchronously\n    }\n)\n\n# Set the objective function\nscheduler.set_objective_function(my_objective_function)\n\n# Run the optimization\nbest_params = scheduler.run_optimization(max_trials=20)\n</code></pre>"},{"location":"api/job/","title":"Job","text":"<p>The <code>Job</code> class represents a unit of work that can be executed by a runner. Jobs can be Python functions, scripts, or containers.</p>"},{"location":"api/job/#class-definition","title":"Class Definition","text":"<pre><code>class Job:\n    def __init__(self, \n                 job_id: str, \n                 job_type: JobType = JobType.FUNCTION,\n                 function: Optional[Callable] = None, \n                 script_path: Optional[str] = None,\n                 container_image: Optional[str] = None,\n                 container_command: Optional[str] = None,\n                 params: Dict[str, Any] = None,\n                 env_vars: Dict[str, str] = None,\n                 working_dir: Optional[str] = None,\n                 output_files: Optional[List[str]] = None):\n        \"\"\"\n        Initialize a new job.\n\n        Args:\n            job_id: Unique identifier for the job\n            job_type: Type of job (FUNCTION, SCRIPT, or CONTAINER)\n            function: The function to run for this job (if job_type is FUNCTION)\n            script_path: Path to the script to run (if job_type is SCRIPT)\n            container_image: Container image to run (if job_type is CONTAINER)\n            container_command: Command to run in the container (if job_type is CONTAINER)\n            params: Parameters to pass to the function or script\n            env_vars: Environment variables to set for the job\n            working_dir: Working directory for the job\n            output_files: List of output files to capture\n        \"\"\"\n</code></pre>"},{"location":"api/job/#job-types","title":"Job Types","text":"<p>The <code>JobType</code> enum defines the supported job types:</p> <pre><code>class JobType(Enum):\n    \"\"\"Type of job to run.\"\"\"\n    FUNCTION = \"function\"  # Python function\n    SCRIPT = \"script\"      # Shell script or Python script\n    CONTAINER = \"container\"  # Docker/Singularity container\n</code></pre>"},{"location":"api/job/#job-states","title":"Job States","text":"<p>The <code>JobState</code> enum defines the possible states of a job:</p> <pre><code>class JobState(Enum):\n    \"\"\"Possible states for a job.\"\"\"\n    CREATED = \"created\"    # Job has been created\n    QUEUED = \"queued\"      # Job is in the queue\n    RUNNING = \"running\"    # Job is currently running\n    COMPLETED = \"completed\"  # Job has completed successfully\n    FAILED = \"failed\"      # Job has failed\n    CANCELLED = \"cancelled\"  # Job was cancelled\n</code></pre>"},{"location":"api/job/#key-methods","title":"Key Methods","text":""},{"location":"api/job/#job-execution","title":"Job Execution","text":"<pre><code>def run(self, runner: \"BaseRunner\") -&gt; None:\n    \"\"\"\n    Run this job using the provided runner.\n\n    Args:\n        runner: The runner to use for execution\n    \"\"\"\n</code></pre>"},{"location":"api/job/#result-handling","title":"Result Handling","text":"<pre><code>def set_result(self, result: Any) -&gt; None:\n    \"\"\"\n    Set the result of this job.\n\n    Args:\n        result: The result of the job\n    \"\"\"\n</code></pre> <pre><code>def get_result(self) -&gt; Any:\n    \"\"\"\n    Get the result of this job.\n\n    Returns:\n        The result of the job\n    \"\"\"\n</code></pre>"},{"location":"api/job/#state-management","title":"State Management","text":"<pre><code>def update_state(self, state: JobState) -&gt; None:\n    \"\"\"\n    Update the state of this job.\n\n    Args:\n        state: The new state\n    \"\"\"\n</code></pre>"},{"location":"api/job/#example-usage","title":"Example Usage","text":""},{"location":"api/job/#function-job","title":"Function Job","text":"<pre><code>from scheduler import Job, JobType\n\n# Create a function job\ndef my_function(x, y):\n    return x + y\n\njob = Job(\n    job_id=\"job1\",\n    job_type=JobType.FUNCTION,\n    function=my_function,\n    params={\"x\": 1, \"y\": 2}\n)\n</code></pre>"},{"location":"api/job/#script-job","title":"Script Job","text":"<pre><code># Create a script job\njob = Job(\n    job_id=\"job2\",\n    job_type=JobType.SCRIPT,\n    script_path=\"./my_script.py\",\n    params={\"input_file\": \"data.csv\", \"output_file\": \"results.csv\"},\n    env_vars={\"DEBUG\": \"1\"}\n)\n</code></pre>"},{"location":"api/job/#container-job","title":"Container Job","text":"<pre><code># Create a container job\njob = Job(\n    job_id=\"job3\",\n    job_type=JobType.CONTAINER,\n    container_image=\"python:3.9\",\n    container_command=\"python /app/script.py\",\n    params={\"threshold\": 0.5},\n    working_dir=\"/app\",\n    output_files=[\"results.json\"]\n)\n</code></pre>"},{"location":"api/runners/","title":"Runners","text":"<p>Runners are responsible for executing jobs on different systems. The Scheduler library provides several runners for different execution environments.</p>"},{"location":"api/runners/#baserunner","title":"BaseRunner","text":"<p>The <code>BaseRunner</code> is an abstract base class that defines the interface for all runners.</p> <pre><code>class BaseRunner(ABC):\n    def __init__(self, config: Dict[str, Any] = None):\n        \"\"\"\n        Initialize a new runner.\n\n        Args:\n            config: Configuration for the runner\n        \"\"\"\n</code></pre>"},{"location":"api/runners/#key-methods","title":"Key Methods","text":"<pre><code>@abstractmethod\ndef run_job(self, job: Job) -&gt; None:\n    \"\"\"\n    Run a job.\n\n    Args:\n        job: The job to run\n    \"\"\"\n</code></pre> <pre><code>@abstractmethod\ndef check_job_status(self, job: Job) -&gt; None:\n    \"\"\"\n    Check the status of a job and update its state.\n\n    Args:\n        job: The job to check\n    \"\"\"\n</code></pre> <pre><code>@abstractmethod\ndef cancel_job(self, job: Job) -&gt; None:\n    \"\"\"\n    Cancel a job.\n\n    Args:\n        job: The job to cancel\n    \"\"\"\n</code></pre>"},{"location":"api/runners/#joblibrunner","title":"JobLibRunner","text":"<p>The <code>JobLibRunner</code> executes jobs locally using joblib for parallelization.</p> <pre><code>class JobLibRunner(BaseRunner):\n    def __init__(self, n_jobs: int = -1, backend: str = 'loky', config: Dict[str, Any] = None):\n        \"\"\"\n        Initialize a new JobLibRunner.\n\n        Args:\n            n_jobs: Number of parallel jobs (-1 for all cores)\n            backend: Joblib backend ('loky', 'threading', or 'multiprocessing')\n            config: Additional configuration\n        \"\"\"\n</code></pre>"},{"location":"api/runners/#configuration-options","title":"Configuration Options","text":"Option Type Default Description <code>container_engine</code> str None Container engine to use ('docker' or 'singularity') <code>tmp_dir</code> str './tmp' Directory for temporary files"},{"location":"api/runners/#slurmrunner","title":"SlurmRunner","text":"<p>The <code>SlurmRunner</code> executes jobs on a Slurm cluster.</p> <pre><code>class SlurmRunner(BaseRunner):\n    def __init__(self, \n                 partition: str,\n                 time_limit: str = \"01:00:00\",\n                 memory: str = \"4G\",\n                 cpus_per_task: int = 1,\n                 config: Dict[str, Any] = None):\n        \"\"\"\n        Initialize a new SlurmRunner.\n\n        Args:\n            partition: Slurm partition to use\n            time_limit: Time limit for jobs (format: HH:MM:SS)\n            memory: Memory allocation for jobs\n            cpus_per_task: Number of CPUs per task\n            config: Additional configuration\n        \"\"\"\n</code></pre>"},{"location":"api/runners/#configuration-options_1","title":"Configuration Options","text":"Option Type Default Description <code>modules</code> List[str] [] Modules to load in the Slurm job <code>sbatch_options</code> Dict[str, str] {} Additional options for sbatch"},{"location":"api/runners/#pandarunner","title":"PanDARunner","text":"<p>The <code>PanDARunner</code> executes jobs on the PanDA distributed computing system.</p> <pre><code>class PanDARunner(BaseRunner):\n    def __init__(self, \n                 site: str,\n                 queue: str,\n                 config: Dict[str, Any] = None):\n        \"\"\"\n        Initialize a new PanDARunner.\n\n        Args:\n            site: PanDA site to use\n            queue: PanDA queue to use\n            config: Additional configuration\n        \"\"\"\n</code></pre>"},{"location":"api/runners/#configuration-options_2","title":"Configuration Options","text":"Option Type Default Description <code>container_image</code> str None Container image to use for jobs <code>resource_type</code> str 'GRID' PanDA resource type"},{"location":"api/runners/#example-usage","title":"Example Usage","text":""},{"location":"api/runners/#joblibrunner_1","title":"JobLibRunner","text":"<pre><code>from scheduler import JobLibRunner\n\n# Create a runner for local parallel execution\nrunner = JobLibRunner(\n    n_jobs=4,  # Use 4 cores\n    backend='loky',  # Use the loky backend\n    config={\n        'tmp_dir': './job_tmp'  # Use a custom temp directory\n    }\n)\n</code></pre>"},{"location":"api/runners/#slurmrunner_1","title":"SlurmRunner","text":"<pre><code>from scheduler import SlurmRunner\n\n# Create a runner for Slurm execution\nrunner = SlurmRunner(\n    partition=\"compute\",\n    time_limit=\"02:00:00\",  # 2 hours\n    memory=\"8G\",\n    cpus_per_task=4,\n    config={\n        'modules': ['python/3.9', 'singularity'],\n        'sbatch_options': {\n            'account': 'my-project',\n            'mail-user': 'user@example.com',\n            'mail-type': 'END,FAIL'\n        }\n    }\n)\n</code></pre>"},{"location":"api/runners/#pandarunner_1","title":"PanDARunner","text":"<pre><code>from scheduler import PanDARunner\n\n# Create a runner for PanDA execution\nrunner = PanDARunner(\n    site=\"CERN-PROD\",\n    queue=\"ATLAS\",\n    config={\n        'container_image': 'docker://atlas/athena:latest',\n        'resource_type': 'GRID'\n    }\n)\n</code></pre>"},{"location":"api/trial/","title":"Trial","text":"<p>The <code>Trial</code> class represents an optimization trial that contains one or more jobs. It extends the functionality of Ax trials with additional features for state tracking and job management.</p>"},{"location":"api/trial/#class-definition","title":"Class Definition","text":"<pre><code>class Trial:\n    def __init__(self, trial_id: str, parameters: Dict[str, Any]):\n        \"\"\"\n        Initialize a new trial.\n\n        Args:\n            trial_id: Unique identifier for the trial\n            parameters: Dictionary of parameters for this trial\n        \"\"\"\n</code></pre>"},{"location":"api/trial/#trial-states","title":"Trial States","text":"<p>The <code>TrialState</code> enum defines the possible states of a trial:</p> <pre><code>class TrialState(Enum):\n    \"\"\"Possible states for a trial.\"\"\"\n    CREATED = \"created\"      # Trial has been created\n    QUEUED = \"queued\"        # Trial is in the queue\n    RUNNING = \"running\"      # Trial is currently running\n    COMPLETED = \"completed\"  # Trial has completed successfully\n    FAILED = \"failed\"        # Trial has failed\n    CANCELLED = \"cancelled\"  # Trial was cancelled\n</code></pre>"},{"location":"api/trial/#key-methods","title":"Key Methods","text":""},{"location":"api/trial/#job-management","title":"Job Management","text":"<pre><code>def add_job(self, job: Job) -&gt; None:\n    \"\"\"\n    Add a job to this trial.\n\n    Args:\n        job: The job to add\n    \"\"\"\n</code></pre>"},{"location":"api/trial/#trial-execution","title":"Trial Execution","text":"<pre><code>def run(self) -&gt; None:\n    \"\"\"\n    Run all jobs in this trial.\n    \"\"\"\n</code></pre>"},{"location":"api/trial/#result-handling","title":"Result Handling","text":"<pre><code>def set_results(self, results: Dict[str, Any]) -&gt; None:\n    \"\"\"\n    Set the results of this trial.\n\n    Args:\n        results: Dictionary of metric results\n    \"\"\"\n</code></pre> <pre><code>def get_results(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Get the results of this trial.\n\n    Returns:\n        Dictionary of metric results\n    \"\"\"\n</code></pre>"},{"location":"api/trial/#state-management","title":"State Management","text":"<pre><code>def update_state(self, state: TrialState) -&gt; None:\n    \"\"\"\n    Update the state of this trial.\n\n    Args:\n        state: The new state\n    \"\"\"\n</code></pre> <pre><code>def check_status(self) -&gt; TrialState:\n    \"\"\"\n    Check the status of this trial by checking all jobs.\n\n    Returns:\n        The current state of the trial\n    \"\"\"\n</code></pre>"},{"location":"api/trial/#trial-timing","title":"Trial Timing","text":"<p>Trials track timing information:</p> <ul> <li><code>creation_time</code>: When the trial was created</li> <li><code>start_time</code>: When the trial started running</li> <li><code>end_time</code>: When the trial completed (successfully or not)</li> </ul> <pre><code>def get_duration(self) -&gt; Optional[float]:\n    \"\"\"\n    Get the duration of this trial in seconds.\n\n    Returns:\n        Duration in seconds, or None if the trial hasn't completed\n    \"\"\"\n</code></pre>"},{"location":"api/trial/#example-usage","title":"Example Usage","text":"<pre><code>from scheduler import Trial, Job, JobType, TrialState\n\n# Create a trial\ntrial = Trial(trial_id=\"trial1\", parameters={\"x\": 0.5, \"y\": 0.7})\n\n# Add a job to the trial\njob = Job(\n    job_id=\"job1\",\n    job_type=JobType.FUNCTION,\n    function=my_objective_function,\n    params=trial.parameters\n)\ntrial.add_job(job)\n\n# Run the trial\ntrial.run()\n\n# Check if the trial is completed\nif trial.state == TrialState.COMPLETED:\n    results = trial.get_results()\n    print(f\"Trial completed with results: {results}\")\n</code></pre>"},{"location":"assets/","title":"Please add the AID2E logo image here","text":"<p>To use the logo image, you need to:</p> <ol> <li>Save the image you shared to this directory as <code>logo.png</code></li> <li>Create a smaller version for the favicon as <code>favicon.png</code> (ideally 32x32px or 64x64px)</li> </ol> <p>You can do this by downloading the image you shared and copying it to this directory manually.</p>"},{"location":"tutorials/","title":"Tutorials","text":"<p>This section provides step-by-step tutorials for common use cases of the Scheduler library.</p>"},{"location":"tutorials/#basic-tutorials","title":"Basic Tutorials","text":"<ul> <li>Basic Detector Optimization: Learn how to optimize detector parameters using a simple objective function</li> <li>Script-Based Optimization: Use external scripts for your optimization objective</li> <li>Container-Based Optimization: Run containerized applications as optimization objectives</li> </ul>"},{"location":"tutorials/#advanced-tutorials","title":"Advanced Tutorials","text":"<ul> <li>Using Slurm for Execution: Scale up your optimization with Slurm cluster computing</li> <li>Using PanDA for Execution: Distribute optimization trials across the grid with PanDA</li> <li>Batch Trial Submission: Submit multiple trials in parallel for efficient exploration</li> <li>Asynchronous Execution: Run trials asynchronously for better resource utilization</li> <li>Experiment Persistence: Save and load experiments to resume optimization</li> </ul>"},{"location":"tutorials/asynchronous_execution/","title":"Asynchronous Execution","text":"<p>Work in Progress</p> <p>This documentation page is currently under development. Check back soon for complete information.</p> <p>This tutorial explains how to use asynchronous execution with the Scheduler for AID2E.</p>"},{"location":"tutorials/asynchronous_execution/#overview","title":"Overview","text":"<p>Asynchronous execution allows you to run multiple optimization trials in parallel without blocking, which can significantly speed up the optimization process.</p>"},{"location":"tutorials/asynchronous_execution/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic understanding of Ax optimization</li> <li>A working installation of Scheduler for AID2E</li> </ul>"},{"location":"tutorials/asynchronous_execution/#implementation","title":"Implementation","text":"<p>More detailed documentation coming soon.</p>"},{"location":"tutorials/asynchronous_execution/#examples","title":"Examples","text":"<p>Code examples will be provided in future updates.</p>"},{"location":"tutorials/batch_trial_submission/","title":"Tutorial: Batch Trial Submission","text":"<p>This tutorial demonstrates how to use the batch trial submission feature of the Scheduler library. Batch trials allow you to submit multiple trials at once, which can be more efficient than submitting them one by one.</p>"},{"location":"tutorials/batch_trial_submission/#prerequisites","title":"Prerequisites","text":"<ul> <li>Scheduler library installed</li> <li>Basic understanding of the Scheduler and Ax</li> </ul>"},{"location":"tutorials/batch_trial_submission/#step-1-import-required-libraries","title":"Step 1: Import Required Libraries","text":"<pre><code>from ax.service.ax_client import AxClient\nfrom scheduler import AxScheduler, JobLibRunner\n</code></pre>"},{"location":"tutorials/batch_trial_submission/#step-2-define-your-objective-function","title":"Step 2: Define Your Objective Function","text":"<pre><code>def objective_function(parameterization):\n    \"\"\"Simple objective function for demonstration.\"\"\"\n    x = parameterization[\"x\"]\n    y = parameterization[\"y\"]\n\n    # Simple objective function: Rosenbrock function\n    a = 1\n    b = 100\n    objective = (a - x)**2 + b * (y - x**2)**2\n\n    return {\"objective\": objective}\n</code></pre>"},{"location":"tutorials/batch_trial_submission/#step-3-initialize-ax-client-and-define-parameter-space","title":"Step 3: Initialize Ax Client and Define Parameter Space","text":"<pre><code># Initialize Ax client\nax_client = AxClient()\n\n# Define the parameter space\nax_client.create_experiment(\n    name=\"batch_trial_demo\",\n    parameters=[\n        {\n            \"name\": \"x\",\n            \"type\": \"range\",\n            \"bounds\": [-2.0, 2.0],\n            \"value_type\": \"float\",\n        },\n        {\n            \"name\": \"y\",\n            \"type\": \"range\",\n            \"bounds\": [-2.0, 2.0],\n            \"value_type\": \"float\",\n        },\n    ],\n    objectives={\"objective\": \"minimize\"},\n)\n</code></pre>"},{"location":"tutorials/batch_trial_submission/#step-4-create-a-runner-and-scheduler","title":"Step 4: Create a Runner and Scheduler","text":"<pre><code># Create a runner for local execution\nrunner = JobLibRunner(n_jobs=4)  # Use 4 cores\n\n# Create the scheduler\nscheduler = AxScheduler(ax_client, runner)\n\n# Set the objective function\nscheduler.set_objective_function(objective_function)\n</code></pre>"},{"location":"tutorials/batch_trial_submission/#step-5-use-batch-trial-context","title":"Step 5: Use Batch Trial Context","text":"<pre><code># Create a batch of trials\nwith scheduler.batch_trial_context() as batch:\n    # Add trials with specific parameter values\n    batch.add_trial({\"x\": 0.5, \"y\": 0.5})\n    batch.add_trial({\"x\": -0.5, \"y\": 0.5})\n    batch.add_trial({\"x\": 0.5, \"y\": -0.5})\n    batch.add_trial({\"x\": -0.5, \"y\": -0.5})\n\n    # The trials will be run when exiting the context\n</code></pre>"},{"location":"tutorials/batch_trial_submission/#step-6-run-additional-optimization","title":"Step 6: Run Additional Optimization","text":"<pre><code># Run more trials using standard optimization\nbest_params = scheduler.run_optimization(max_trials=10)\n\n# Print the results\nprint(\"Best parameters:\")\nprint(best_params)\n</code></pre>"},{"location":"tutorials/batch_trial_submission/#complete-example","title":"Complete Example","text":"<p>Here's the complete example:</p> <pre><code>from ax.service.ax_client import AxClient\nfrom scheduler import AxScheduler, JobLibRunner\n\ndef objective_function(parameterization):\n    \"\"\"Simple objective function for demonstration.\"\"\"\n    x = parameterization[\"x\"]\n    y = parameterization[\"y\"]\n\n    # Simple objective function: Rosenbrock function\n    a = 1\n    b = 100\n    objective = (a - x)**2 + b * (y - x**2)**2\n\n    return {\"objective\": objective}\n\ndef main():\n    # Initialize Ax client\n    ax_client = AxClient()\n\n    # Define the parameter space\n    ax_client.create_experiment(\n        name=\"batch_trial_demo\",\n        parameters=[\n            {\n                \"name\": \"x\",\n                \"type\": \"range\",\n                \"bounds\": [-2.0, 2.0],\n                \"value_type\": \"float\",\n            },\n            {\n                \"name\": \"y\",\n                \"type\": \"range\",\n                \"bounds\": [-2.0, 2.0],\n                \"value_type\": \"float\",\n            },\n        ],\n        objectives={\"objective\": \"minimize\"},\n    )\n\n    # Create a runner for local execution\n    runner = JobLibRunner(n_jobs=4)  # Use 4 cores\n\n    # Create the scheduler\n    scheduler = AxScheduler(ax_client, runner)\n\n    # Set the objective function\n    scheduler.set_objective_function(objective_function)\n\n    # Create a batch of trials with manually specified values\n    print(\"Running batch of manually specified trials...\")\n    with scheduler.batch_trial_context() as batch:\n        # Add trials with specific parameter values\n        batch.add_trial({\"x\": 0.5, \"y\": 0.5})\n        batch.add_trial({\"x\": -0.5, \"y\": 0.5})\n        batch.add_trial({\"x\": 0.5, \"y\": -0.5})\n        batch.add_trial({\"x\": -0.5, \"y\": -0.5})\n\n    # Print results of the batch trials\n    print(\"\\nResults from batch trials:\")\n    for trial_idx in range(ax_client.experiment.num_trials):\n        trial = ax_client.experiment.trials[trial_idx]\n        params = trial.arm.parameters\n        metrics = trial.objective_mean\n        print(f\"Trial {trial_idx}: Params {params}, Objective: {metrics}\")\n\n    # Run more trials using standard optimization\n    print(\"\\nRunning additional optimization trials...\")\n    best_params = scheduler.run_optimization(max_trials=6)  # 6 more trials\n\n    # Print the final results\n    print(\"\\nBest parameters after all trials:\")\n    print(best_params)\n\n    # Save the experiment for later analysis\n    scheduler.save_experiment(\"batch_trial_results.json\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"tutorials/batch_trial_submission/#advanced-batch-trials-with-ax-generation-strategy","title":"Advanced: Batch Trials with Ax Generation Strategy","text":"<p>You can also combine batch trials with Ax's generation strategy to generate multiple parameter sets at once:</p> <pre><code># Create a batch of model-generated trials\nprint(\"Running batch of model-generated trials...\")\nwith scheduler.batch_trial_context() as batch:\n    # Generate multiple parameter sets using the model\n    for _ in range(4):\n        parameters, trial_index = ax_client.get_next_trial()\n        # Add the trial to the batch\n        batch.add_trial(parameters)\n</code></pre>"},{"location":"tutorials/batch_trial_submission/#advanced-asynchronous-batch-execution","title":"Advanced: Asynchronous Batch Execution","text":"<p>For more efficient resource utilization, you can run batch trials asynchronously:</p> <pre><code># Create the scheduler with asynchronous execution\nscheduler = AxScheduler(\n    ax_client, \n    runner,\n    config={\n        'synchronous': False,  # Run trials asynchronously\n        'monitoring_interval': 1  # Check status every second\n    }\n)\n\n# Set the objective function\nscheduler.set_objective_function(objective_function)\n\n# Create an asynchronous batch of trials\nwith scheduler.batch_trial_context() as batch:\n    for _ in range(10):\n        parameters, trial_index = ax_client.get_next_trial()\n        batch.add_trial(parameters)\n\n# Wait for all trials to complete\nscheduler.wait_for_completed_trials()\n</code></pre>"},{"location":"tutorials/batch_trial_submission/#next-steps","title":"Next Steps","text":"<ul> <li>Combine batch trials with Slurm Execution for high-performance computing</li> <li>Use batch trials with Container-Based Optimization for reproducible experiments</li> <li>Learn about saving and loading experiments in the Experiment Persistence tutorial</li> </ul>"},{"location":"tutorials/container_based_optimization/","title":"Tutorial: Container-Based Optimization","text":"<p>This tutorial demonstrates how to use the Scheduler library with containers (Docker or Singularity) for optimization tasks. Containers provide consistent execution environments and can help ensure reproducibility of results.</p>"},{"location":"tutorials/container_based_optimization/#prerequisites","title":"Prerequisites","text":"<ul> <li>Scheduler library installed</li> <li>Docker or Singularity installed on your system</li> <li>Basic understanding of containers</li> </ul>"},{"location":"tutorials/container_based_optimization/#step-1-prepare-your-container","title":"Step 1: Prepare Your Container","text":"<p>First, you need a container image that includes your simulation or analysis code. Here's an example Dockerfile:</p> <pre><code># Use a suitable base image\nFROM python:3.9-slim\n\n# Install dependencies\nRUN pip install numpy scipy pandas matplotlib\n\n# Copy your simulation code\nCOPY simulation.py /app/simulation.py\n\n# Set the working directory\nWORKDIR /app\n\n# The container will be run with the command passed via the scheduler\n</code></pre> <p>Build the container image:</p> <pre><code>docker build -t epic-simulation:latest .\n</code></pre>"},{"location":"tutorials/container_based_optimization/#step-2-import-required-libraries","title":"Step 2: Import Required Libraries","text":"<pre><code>from ax.service.ax_client import AxClient\nfrom scheduler import AxScheduler, JobLibRunner\n</code></pre>"},{"location":"tutorials/container_based_optimization/#step-3-initialize-ax-client-and-define-parameter-space","title":"Step 3: Initialize Ax Client and Define Parameter Space","text":"<pre><code># Initialize Ax client\nax_client = AxClient()\n\n# Define the parameter space\nax_client.create_experiment(\n    name=\"container_detector_optimization\",\n    parameters=[\n        {\n            \"name\": \"field_strength\",\n            \"type\": \"range\",\n            \"bounds\": [1.0, 3.0],\n            \"value_type\": \"float\",\n        },\n        {\n            \"name\": \"detector_length\",\n            \"type\": \"range\",\n            \"bounds\": [4.0, 8.0],\n            \"value_type\": \"float\",\n        },\n        {\n            \"name\": \"detector_radius\",\n            \"type\": \"range\",\n            \"bounds\": [1.0, 3.0],\n            \"value_type\": \"float\",\n        },\n    ],\n    objectives={\n        \"resolution\": \"minimize\",\n        \"acceptance\": \"maximize\",\n    },\n    outcome_constraints=[\"cost &lt;= 100.0\"],\n)\n</code></pre>"},{"location":"tutorials/container_based_optimization/#step-4-create-a-runner-with-container-support","title":"Step 4: Create a Runner with Container Support","text":"<pre><code># Create a runner with container support\nrunner = JobLibRunner(\n    n_jobs=4,  # Use 4 cores\n    config={\n        'container_engine': 'docker',  # or 'singularity'\n        'tmp_dir': './container_tmp'   # Directory for temporary files\n    }\n)\n</code></pre>"},{"location":"tutorials/container_based_optimization/#step-5-create-the-scheduler-and-set-container-objective","title":"Step 5: Create the Scheduler and Set Container Objective","text":"<pre><code># Create the scheduler\nscheduler = AxScheduler(\n    ax_client, \n    runner,\n    config={\n        'job_output_dir': './container_outputs',  # Directory for job outputs\n        'monitoring_interval': 10                 # Check status every 10 seconds\n    }\n)\n\n# Set the container objective\nscheduler.set_container_objective(\n    container_image=\"epic-simulation:latest\",\n    container_command=\"python simulation.py {params_file} {output_file}\",\n    container_options={\n        'volumes': {\n            './data': '/app/data',  # Mount local data directory\n        },\n        'env_vars': {\n            'DEBUG': '1'\n        }\n    }\n)\n</code></pre> <p>The <code>{params_file}</code> and <code>{output_file}</code> placeholders will be automatically replaced with the paths to the parameter and output files.</p>"},{"location":"tutorials/container_based_optimization/#step-6-run-the-optimization","title":"Step 6: Run the Optimization","text":"<pre><code># Run the optimization\nbest_params = scheduler.run_optimization(max_trials=20)\n\n# Print the results\nprint(\"Best parameters:\")\nprint(best_params)\n\n# Get the best metrics\nbest_metrics = ax_client.get_best_trial().values\nprint(\"Best metrics:\")\nprint(best_metrics)\n</code></pre>"},{"location":"tutorials/container_based_optimization/#complete-example","title":"Complete Example","text":"<p>Here's the complete example:</p> <pre><code>import os\nfrom ax.service.ax_client import AxClient\nfrom scheduler import AxScheduler, JobLibRunner\n\ndef main():\n    # Initialize Ax client\n    ax_client = AxClient()\n\n    # Define the parameter space\n    ax_client.create_experiment(\n        name=\"container_detector_optimization\",\n        parameters=[\n            {\n                \"name\": \"field_strength\",\n                \"type\": \"range\",\n                \"bounds\": [1.0, 3.0],\n                \"value_type\": \"float\",\n            },\n            {\n                \"name\": \"detector_length\",\n                \"type\": \"range\",\n                \"bounds\": [4.0, 8.0],\n                \"value_type\": \"float\",\n            },\n            {\n                \"name\": \"detector_radius\",\n                \"type\": \"range\",\n                \"bounds\": [1.0, 3.0],\n                \"value_type\": \"float\",\n            },\n        ],\n        objectives={\n            \"resolution\": \"minimize\",\n            \"acceptance\": \"maximize\",\n        },\n        outcome_constraints=[\"cost &lt;= 100.0\"],\n    )\n\n    # Create directories\n    os.makedirs('./container_tmp', exist_ok=True)\n    os.makedirs('./container_outputs', exist_ok=True)\n\n    # Create a runner with container support\n    runner = JobLibRunner(\n        n_jobs=4,  # Use 4 cores\n        config={\n            'container_engine': 'docker',  # or 'singularity'\n            'tmp_dir': './container_tmp'   # Directory for temporary files\n        }\n    )\n\n    # Create the scheduler\n    scheduler = AxScheduler(\n        ax_client, \n        runner,\n        config={\n            'job_output_dir': './container_outputs',  # Directory for job outputs\n            'monitoring_interval': 10                 # Check status every 10 seconds\n        }\n    )\n\n    # Set the container objective\n    scheduler.set_container_objective(\n        container_image=\"epic-simulation:latest\",\n        container_command=\"python simulation.py {params_file} {output_file}\",\n        container_options={\n            'volumes': {\n                './data': '/app/data',  # Mount local data directory\n            },\n            'env_vars': {\n                'DEBUG': '1'\n            }\n        }\n    )\n\n    # Run the optimization\n    best_params = scheduler.run_optimization(max_trials=20)\n\n    # Print the results\n    print(\"Best parameters:\")\n    print(best_params)\n\n    # Get the best metrics\n    best_metrics = ax_client.get_best_trial().values\n    print(\"Best metrics:\")\n    print(best_metrics)\n\n    # Save the experiment for later analysis\n    scheduler.save_experiment(\"container_optimization_results.json\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"tutorials/container_based_optimization/#example-simulation-code-for-container","title":"Example Simulation Code for Container","text":"<p>Here's an example simulation script (<code>simulation.py</code>) that would run inside the container:</p> <pre><code>#!/usr/bin/env python\nimport sys\nimport json\nimport numpy as np\n\ndef main():\n    # Parse input parameters\n    with open(sys.argv[1], 'r') as f:\n        params = json.load(f)\n\n    # Extract parameters\n    field_strength = params['field_strength']\n    detector_length = params['detector_length']\n    detector_radius = params['detector_radius']\n\n    # Simulate detector performance\n    # Better resolution (lower is better) with higher field and larger size\n    resolution = 0.1 / field_strength * (1 + np.exp(-detector_length)) * (1 + np.exp(-detector_radius))\n\n    # Better acceptance (higher is better) with larger detector\n    acceptance = (1 - np.exp(-detector_length * detector_radius)) * 100\n\n    # Higher cost with larger detector and stronger field\n    cost = field_strength * 2 + detector_length * 10 + detector_radius * 15\n\n    # Write output\n    results = {\n        \"resolution\": float(resolution),\n        \"acceptance\": float(acceptance),\n        \"cost\": float(cost)\n    }\n\n    with open(sys.argv[2], 'w') as f:\n        json.dump(results, f)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"tutorials/container_based_optimization/#using-singularity-instead-of-docker","title":"Using Singularity Instead of Docker","text":"<p>If you're using Singularity instead of Docker, change the <code>container_engine</code> configuration:</p> <pre><code>runner = JobLibRunner(\n    n_jobs=4,\n    config={\n        'container_engine': 'singularity',\n        'tmp_dir': './container_tmp'\n    }\n)\n</code></pre> <p>You might also need to adjust the container image reference:</p> <pre><code>scheduler.set_container_objective(\n    container_image=\"docker://username/epic-simulation:latest\",  # Docker image via Singularity\n    # OR\n    # container_image=\"/path/to/epic-simulation.sif\",  # Singularity image file\n    container_command=\"python simulation.py {params_file} {output_file}\"\n)\n</code></pre>"},{"location":"tutorials/container_based_optimization/#using-containers-with-slurm","title":"Using Containers with Slurm","text":"<p>You can also use containers with the SlurmRunner:</p> <pre><code>from scheduler import SlurmRunner\n\nrunner = SlurmRunner(\n    partition=\"compute\",\n    time_limit=\"01:00:00\",\n    memory=\"4G\",\n    cpus_per_task=4,\n    config={\n        'modules': ['singularity'],  # Load the Singularity module\n        'sbatch_options': {\n            'account': 'my-project'\n        }\n    }\n)\n\nscheduler = AxScheduler(ax_client, runner)\nscheduler.set_container_objective(\n    container_image=\"docker://username/epic-simulation:latest\",\n    container_command=\"python simulation.py {params_file} {output_file}\"\n)\n</code></pre>"},{"location":"tutorials/container_based_optimization/#next-steps","title":"Next Steps","text":"<ul> <li>Try combining containers with Slurm execution for scalable, reproducible optimization</li> <li>Explore saving and loading container-based experiments in the Experiment Persistence tutorial</li> <li>Learn about batch trial submission in the Batch Trial Submission tutorial</li> </ul>"},{"location":"tutorials/container_jobs/","title":"Container Jobs","text":"<p>Work in Progress</p> <p>This documentation page is currently under development. Check back soon for complete information.</p> <p>This tutorial explains how to use container jobs with the Scheduler for AID2E.</p>"},{"location":"tutorials/container_jobs/#overview","title":"Overview","text":"<p>Container jobs allow you to package your optimization workloads in containers (Docker, Singularity, etc.) for better portability and reproducibility.</p>"},{"location":"tutorials/container_jobs/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic understanding of container technologies (Docker, Singularity)</li> <li>A working installation of Scheduler for AID2E</li> </ul>"},{"location":"tutorials/container_jobs/#implementation","title":"Implementation","text":"<p>More detailed documentation coming soon.</p>"},{"location":"tutorials/container_jobs/#examples","title":"Examples","text":"<p>Code examples will be provided in future updates.</p>"},{"location":"tutorials/detector_optimization/","title":"Tutorial: Basic Detector Optimization","text":"<p>This tutorial shows how to use the Scheduler library for optimizing detector parameters. We'll create a simple objective function that evaluates detector performance based on field strength, detector length, and detector radius.</p>"},{"location":"tutorials/detector_optimization/#prerequisites","title":"Prerequisites","text":"<ul> <li>Scheduler library installed (see Installation)</li> <li>Basic understanding of Bayesian optimization with Ax</li> </ul>"},{"location":"tutorials/detector_optimization/#step-1-import-required-libraries","title":"Step 1: Import Required Libraries","text":"<pre><code>import numpy as np\nfrom ax.service.ax_client import AxClient\nfrom scheduler import AxScheduler, JobLibRunner\n</code></pre>"},{"location":"tutorials/detector_optimization/#step-2-define-your-objective-function","title":"Step 2: Define Your Objective Function","text":"<p>Create a function that evaluates detector performance based on the input parameters:</p> <pre><code>def evaluate_detector_design(field_strength, detector_length, detector_radius):\n    \"\"\"\n    Example objective function for ePIC EIC detector optimization.\n\n    Args:\n        field_strength: Magnetic field strength in Tesla\n        detector_length: Detector length in meters\n        detector_radius: Detector radius in meters\n\n    Returns:\n        Dict with metrics: resolution, acceptance, cost\n    \"\"\"\n    # Simulate detector performance\n    # This is a simplified example - replace with actual simulation code\n\n    # For this example, we'll use simplified formulas:\n    # Better resolution (lower is better) with higher field and larger size\n    resolution = 0.1 / field_strength * (1 + np.exp(-detector_length)) * (1 + np.exp(-detector_radius))\n\n    # Better acceptance (higher is better) with larger detector\n    acceptance = (1 - np.exp(-detector_length * detector_radius)) * 100\n\n    # Higher cost with larger detector and stronger field\n    cost = field_strength * 2 + detector_length * 10 + detector_radius * 15\n\n    return {\n        \"resolution\": resolution,  # Lower is better\n        \"acceptance\": acceptance,  # Higher is better\n        \"cost\": cost               # Lower is better\n    }\n</code></pre>"},{"location":"tutorials/detector_optimization/#step-3-create-a-wrapper-function-for-ax","title":"Step 3: Create a Wrapper Function for Ax","text":"<p>Ax requires a specific function signature, so create a wrapper:</p> <pre><code>def optimization_function(parameterization):\n    \"\"\"Wrapper for the objective function to use with Ax.\"\"\"\n    metrics = evaluate_detector_design(\n        field_strength=parameterization[\"field_strength\"],\n        detector_length=parameterization[\"detector_length\"],\n        detector_radius=parameterization[\"detector_radius\"]\n    )\n    return metrics\n</code></pre>"},{"location":"tutorials/detector_optimization/#step-4-initialize-ax-client-and-define-parameter-space","title":"Step 4: Initialize Ax Client and Define Parameter Space","text":"<pre><code># Initialize Ax client\nax_client = AxClient()\n\n# Define the parameter space\nax_client.create_experiment(\n    name=\"epic_detector_optimization\",\n    parameters=[\n        {\n            \"name\": \"field_strength\",\n            \"type\": \"range\",\n            \"bounds\": [1.0, 3.0],\n            \"value_type\": \"float\",\n        },\n        {\n            \"name\": \"detector_length\",\n            \"type\": \"range\",\n            \"bounds\": [4.0, 8.0],\n            \"value_type\": \"float\",\n        },\n        {\n            \"name\": \"detector_radius\",\n            \"type\": \"range\",\n            \"bounds\": [1.0, 3.0],\n            \"value_type\": \"float\",\n        },\n    ],\n    objectives={\n        \"resolution\": \"minimize\",\n        \"acceptance\": \"maximize\",\n    },\n    outcome_constraints=[\"cost &lt;= 100.0\"],\n)\n</code></pre>"},{"location":"tutorials/detector_optimization/#step-5-create-a-runner-and-scheduler","title":"Step 5: Create a Runner and Scheduler","text":"<pre><code># Create a runner for local execution\nrunner = JobLibRunner(n_jobs=4)  # Use 4 cores\n\n# Create the scheduler\nscheduler = AxScheduler(ax_client, runner)\n\n# Set the objective function\nscheduler.set_objective_function(optimization_function)\n</code></pre>"},{"location":"tutorials/detector_optimization/#step-6-run-the-optimization","title":"Step 6: Run the Optimization","text":"<pre><code># Run the optimization\nbest_params = scheduler.run_optimization(max_trials=20)\n\n# Print the results\nprint(\"Best parameters:\")\nprint(best_params)\n\n# Get the best metrics\nbest_metrics = ax_client.get_best_trial().values\nprint(\"Best metrics:\")\nprint(best_metrics)\n</code></pre>"},{"location":"tutorials/detector_optimization/#complete-example","title":"Complete Example","text":"<p>Here's the complete example:</p> <pre><code>import numpy as np\nfrom ax.service.ax_client import AxClient\nfrom scheduler import AxScheduler, JobLibRunner\n\n# Define your objective function for detector optimization\ndef evaluate_detector_design(field_strength, detector_length, detector_radius):\n    \"\"\"\n    Example objective function for ePIC EIC detector optimization.\n\n    Args:\n        field_strength: Magnetic field strength in Tesla\n        detector_length: Detector length in meters\n        detector_radius: Detector radius in meters\n\n    Returns:\n        Dict with metrics: resolution, acceptance, cost\n    \"\"\"\n    # Simulate detector performance\n    # This is a simplified example - replace with actual simulation code\n\n    # For this example, we'll use simplified formulas:\n    # Better resolution (lower is better) with higher field and larger size\n    resolution = 0.1 / field_strength * (1 + np.exp(-detector_length)) * (1 + np.exp(-detector_radius))\n\n    # Better acceptance (higher is better) with larger detector\n    acceptance = (1 - np.exp(-detector_length * detector_radius)) * 100\n\n    # Higher cost with larger detector and stronger field\n    cost = field_strength * 2 + detector_length * 10 + detector_radius * 15\n\n    return {\n        \"resolution\": resolution,  # Lower is better\n        \"acceptance\": acceptance,  # Higher is better\n        \"cost\": cost               # Lower is better\n    }\n\n# Wrapper function for Ax\ndef optimization_function(parameterization):\n    \"\"\"Wrapper for the objective function to use with Ax.\"\"\"\n    metrics = evaluate_detector_design(\n        field_strength=parameterization[\"field_strength\"],\n        detector_length=parameterization[\"detector_length\"],\n        detector_radius=parameterization[\"detector_radius\"]\n    )\n    return metrics\n\ndef main():\n    # Initialize Ax client\n    ax_client = AxClient()\n\n    # Define the parameter space\n    ax_client.create_experiment(\n        name=\"epic_detector_optimization\",\n        parameters=[\n            {\n                \"name\": \"field_strength\",\n                \"type\": \"range\",\n                \"bounds\": [1.0, 3.0],\n                \"value_type\": \"float\",\n            },\n            {\n                \"name\": \"detector_length\",\n                \"type\": \"range\",\n                \"bounds\": [4.0, 8.0],\n                \"value_type\": \"float\",\n            },\n            {\n                \"name\": \"detector_radius\",\n                \"type\": \"range\",\n                \"bounds\": [1.0, 3.0],\n                \"value_type\": \"float\",\n            },\n        ],\n        objectives={\n            \"resolution\": \"minimize\",\n            \"acceptance\": \"maximize\",\n        },\n        outcome_constraints=[\"cost &lt;= 100.0\"],\n    )\n\n    # Create a runner for local execution\n    runner = JobLibRunner(n_jobs=4)  # Use 4 cores\n\n    # Create the scheduler\n    scheduler = AxScheduler(ax_client, runner)\n\n    # Set the objective function\n    scheduler.set_objective_function(optimization_function)\n\n    # Run the optimization\n    best_params = scheduler.run_optimization(max_trials=20)\n\n    # Print the results\n    print(\"Best parameters:\")\n    print(best_params)\n\n    # Get the best metrics\n    best_metrics = ax_client.get_best_trial().values\n    print(\"Best metrics:\")\n    print(best_metrics)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"tutorials/detector_optimization/#next-steps","title":"Next Steps","text":"<ul> <li>Try modifying the objective function to include more realistic detector physics</li> <li>Experiment with different parameter ranges and constraints</li> <li>Check out the Slurm Execution Tutorial to scale up your optimization</li> </ul>"},{"location":"tutorials/experiment_persistence/","title":"Experiment Persistence","text":"<p>This documentation is currently under development.</p> <p>Experiment persistence allows you to save the state of your optimization experiments and resume them later. This is especially useful for long-running experiments or when you need to pause and resume optimization.</p>"},{"location":"tutorials/experiment_persistence/#features","title":"Features","text":"<ul> <li>Save experiment state to disk</li> <li>Resume optimization from a saved state</li> <li>Track optimization history across sessions</li> </ul> <p>Check back soon for the complete documentation.</p>"},{"location":"tutorials/panda_execution/","title":"PANDA Execution","text":"<p>Work in Progress</p> <p>This documentation page is currently under development. Check back soon for complete information.</p> <p>This tutorial explains how to use PANDA execution with the Scheduler for AID2E.</p>"},{"location":"tutorials/panda_execution/#overview","title":"Overview","text":"<p>PANDA (PArticle physics Numerical Data Analysis) is a framework for analyzing physics data. This tutorial covers how to integrate PANDA workflows with the Scheduler.</p>"},{"location":"tutorials/panda_execution/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic understanding of PANDA</li> <li>A working installation of Scheduler for AID2E</li> </ul>"},{"location":"tutorials/panda_execution/#implementation","title":"Implementation","text":"<p>More detailed documentation coming soon.</p>"},{"location":"tutorials/panda_execution/#examples","title":"Examples","text":"<p>Code examples will be provided in future updates.</p>"},{"location":"tutorials/script_based_optimization/","title":"Script-Based Optimization","text":"<p>Work in Progress</p> <p>This documentation page is currently under development. Check back soon for complete information.</p> <p>This tutorial explains how to use script-based optimization with the Scheduler for AID2E.</p>"},{"location":"tutorials/script_based_optimization/#overview","title":"Overview","text":"<p>Script-based optimization allows you to define your optimization objectives using external scripts rather than Python functions.</p>"},{"location":"tutorials/script_based_optimization/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic understanding of Ax optimization</li> <li>A working installation of Scheduler for AID2E</li> </ul>"},{"location":"tutorials/script_based_optimization/#implementation","title":"Implementation","text":"<p>More detailed documentation coming soon.</p>"},{"location":"tutorials/script_based_optimization/#examples","title":"Examples","text":"<p>Code examples will be provided in future updates.</p>"},{"location":"tutorials/slurm_execution/","title":"Tutorial: Using Slurm for Execution","text":"<p>This tutorial demonstrates how to use the Scheduler library with Slurm for running optimization trials on a cluster. Using Slurm allows you to scale up your optimization by distributing trials across multiple compute nodes.</p>"},{"location":"tutorials/slurm_execution/#prerequisites","title":"Prerequisites","text":"<ul> <li>Scheduler library installed with Slurm support (<code>pip install -e .[slurm]</code>)</li> <li>Access to a Slurm cluster</li> <li>Basic understanding of Slurm concepts (partitions, job submission, etc.)</li> </ul>"},{"location":"tutorials/slurm_execution/#step-1-import-required-libraries","title":"Step 1: Import Required Libraries","text":"<pre><code>from ax.service.ax_client import AxClient\nfrom scheduler import AxScheduler, SlurmRunner\n</code></pre>"},{"location":"tutorials/slurm_execution/#step-2-define-your-objective-function","title":"Step 2: Define Your Objective Function","text":"<p>For this example, we'll use a script-based objective instead of a Python function, since this is more common in HPC environments:</p> <pre><code># Create a script file: simulation_script.py\n\"\"\"\n#!/usr/bin/env python\nimport sys\nimport json\nimport numpy as np\n\n# Parse input parameters\nwith open(sys.argv[1], 'r') as f:\n    params = json.load(f)\n\n# Extract parameters\nfield_strength = params['field_strength']\ndetector_length = params['detector_length']\ndetector_radius = params['detector_radius']\n\n# Simulate detector performance\n# Better resolution (lower is better) with higher field and larger size\nresolution = 0.1 / field_strength * (1 + np.exp(-detector_length)) * (1 + np.exp(-detector_radius))\n\n# Better acceptance (higher is better) with larger detector\nacceptance = (1 - np.exp(-detector_length * detector_radius)) * 100\n\n# Higher cost with larger detector and stronger field\ncost = field_strength * 2 + detector_length * 10 + detector_radius * 15\n\n# Write output\nresults = {\n    \"resolution\": float(resolution),\n    \"acceptance\": float(acceptance),\n    \"cost\": float(cost)\n}\n\nwith open(sys.argv[2], 'w') as f:\n    json.dump(results, f)\n\"\"\"\n</code></pre>"},{"location":"tutorials/slurm_execution/#step-3-initialize-ax-client-and-define-parameter-space","title":"Step 3: Initialize Ax Client and Define Parameter Space","text":"<pre><code># Initialize Ax client\nax_client = AxClient()\n\n# Define the parameter space\nax_client.create_experiment(\n    name=\"epic_detector_optimization\",\n    parameters=[\n        {\n            \"name\": \"field_strength\",\n            \"type\": \"range\",\n            \"bounds\": [1.0, 3.0],\n            \"value_type\": \"float\",\n        },\n        {\n            \"name\": \"detector_length\",\n            \"type\": \"range\",\n            \"bounds\": [4.0, 8.0],\n            \"value_type\": \"float\",\n        },\n        {\n            \"name\": \"detector_radius\",\n            \"type\": \"range\",\n            \"bounds\": [1.0, 3.0],\n            \"value_type\": \"float\",\n        },\n    ],\n    objectives={\n        \"resolution\": \"minimize\",\n        \"acceptance\": \"maximize\",\n    },\n    outcome_constraints=[\"cost &lt;= 100.0\"],\n)\n</code></pre>"},{"location":"tutorials/slurm_execution/#step-4-create-a-slurm-runner","title":"Step 4: Create a Slurm Runner","text":"<pre><code># Create a runner for Slurm execution\nrunner = SlurmRunner(\n    partition=\"compute\",       # Specify your partition\n    time_limit=\"00:30:00\",     # 30 minutes per job\n    memory=\"4G\",               # 4GB of memory per job\n    cpus_per_task=4,           # 4 CPUs per task\n    config={\n        'modules': ['python/3.9'],  # Modules to load\n        'sbatch_options': {\n            'account': 'eic-project',       # Your account/allocation\n            'mail-user': 'user@example.com',  # Email for notifications\n            'mail-type': 'END,FAIL'           # When to send notifications\n        }\n    }\n)\n</code></pre>"},{"location":"tutorials/slurm_execution/#step-5-create-the-scheduler-and-set-script-objective","title":"Step 5: Create the Scheduler and Set Script Objective","text":"<pre><code># Create the scheduler\nscheduler = AxScheduler(\n    ax_client, \n    runner,\n    config={\n        'job_output_dir': './slurm_outputs',  # Directory for job outputs\n        'synchronous': False,                  # Run trials asynchronously\n        'monitoring_interval': 30              # Check status every 30 seconds\n    }\n)\n\n# Set the script objective\nscheduler.set_script_objective(\n    script_path=\"./simulation_script.py\",\n    script_options={\n        'interpreter': 'python',  # Use Python to run the script\n        'timeout': 1200           # Timeout in seconds (20 minutes)\n    }\n)\n</code></pre>"},{"location":"tutorials/slurm_execution/#step-6-run-the-optimization","title":"Step 6: Run the Optimization","text":"<pre><code># Run the optimization\nbest_params = scheduler.run_optimization(max_trials=20)\n\n# Print the results\nprint(\"Best parameters:\")\nprint(best_params)\n\n# Get the best metrics\nbest_metrics = ax_client.get_best_trial().values\nprint(\"Best metrics:\")\nprint(best_metrics)\n</code></pre>"},{"location":"tutorials/slurm_execution/#complete-example","title":"Complete Example","text":"<p>Here's the complete example:</p> <pre><code>from ax.service.ax_client import AxClient\nfrom scheduler import AxScheduler, SlurmRunner\nimport os\n\ndef main():\n    # Initialize Ax client\n    ax_client = AxClient()\n\n    # Define the parameter space\n    ax_client.create_experiment(\n        name=\"epic_detector_optimization\",\n        parameters=[\n            {\n                \"name\": \"field_strength\",\n                \"type\": \"range\",\n                \"bounds\": [1.0, 3.0],\n                \"value_type\": \"float\",\n            },\n            {\n                \"name\": \"detector_length\",\n                \"type\": \"range\",\n                \"bounds\": [4.0, 8.0],\n                \"value_type\": \"float\",\n            },\n            {\n                \"name\": \"detector_radius\",\n                \"type\": \"range\",\n                \"bounds\": [1.0, 3.0],\n                \"value_type\": \"float\",\n            },\n        ],\n        objectives={\n            \"resolution\": \"minimize\",\n            \"acceptance\": \"maximize\",\n        },\n        outcome_constraints=[\"cost &lt;= 100.0\"],\n    )\n\n    # Create a runner for Slurm execution\n    runner = SlurmRunner(\n        partition=\"compute\",       # Specify your partition\n        time_limit=\"00:30:00\",     # 30 minutes per job\n        memory=\"4G\",               # 4GB of memory per job\n        cpus_per_task=4,           # 4 CPUs per task\n        config={\n            'modules': ['python/3.9'],  # Modules to load\n            'sbatch_options': {\n                'account': 'eic-project',       # Your account/allocation\n                'mail-user': 'user@example.com',  # Email for notifications\n                'mail-type': 'END,FAIL'           # When to send notifications\n            }\n        }\n    )\n\n    # Create output directory if it doesn't exist\n    os.makedirs('./slurm_outputs', exist_ok=True)\n\n    # Create the scheduler\n    scheduler = AxScheduler(\n        ax_client, \n        runner,\n        config={\n            'job_output_dir': './slurm_outputs',  # Directory for job outputs\n            'synchronous': False,                  # Run trials asynchronously\n            'monitoring_interval': 30              # Check status every 30 seconds\n        }\n    )\n\n    # Set the script objective\n    scheduler.set_script_objective(\n        script_path=\"./simulation_script.py\",\n        script_options={\n            'interpreter': 'python',  # Use Python to run the script\n            'timeout': 1200           # Timeout in seconds (20 minutes)\n        }\n    )\n\n    # Run the optimization\n    best_params = scheduler.run_optimization(max_trials=20)\n\n    # Print the results\n    print(\"Best parameters:\")\n    print(best_params)\n\n    # Get the best metrics\n    best_metrics = ax_client.get_best_trial().values\n    print(\"Best metrics:\")\n    print(best_metrics)\n\n    # Save the experiment for later analysis\n    scheduler.save_experiment(\"slurm_optimization_results.json\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"tutorials/slurm_execution/#monitoring-slurm-jobs","title":"Monitoring Slurm Jobs","text":"<p>You can use standard Slurm commands to monitor your jobs:</p> <pre><code># Check status of all your jobs\nsqueue -u $USER\n\n# Check details of a specific job\nscontrol show job &lt;job_id&gt;\n\n# View the output file of a job\ncat slurm-&lt;job_id&gt;.out\n</code></pre> <p>The Scheduler will also periodically check the status of your jobs and update the trial states accordingly.</p>"},{"location":"tutorials/slurm_execution/#handling-job-failures","title":"Handling Job Failures","text":"<p>If a Slurm job fails, the corresponding trial will be marked as failed. You can check the output files in the <code>job_output_dir</code> directory for error messages.</p>"},{"location":"tutorials/slurm_execution/#next-steps","title":"Next Steps","text":"<ul> <li>Try using containers with Slurm by checking out the Container-Based Optimization tutorial</li> <li>Explore batch trial submission with Slurm in the Batch Trial Submission tutorial</li> <li>Learn how to save and load experiments in the Experiment Persistence tutorial</li> </ul>"}]}